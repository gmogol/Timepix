{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipynb.fs.defs.tdc_data_analysis import line_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces_tdcs(filename=None,debug=False,tdc_df=None):\n",
    "    ''' \n",
    "    Args:\n",
    "        filename : string\n",
    "            name of the file\n",
    "        debug : bool\n",
    "              if True returns all dataframes\n",
    "        tdc_df : pd.DataFrame Object\n",
    "            instead of reading from file one can give the df directly\n",
    "    Returns:\n",
    "        time_df : pd.DataFrame Object\n",
    "            \n",
    "    It takes the data file for TDC's ONLY, which is assumed to be in the form\n",
    "    TDCn: t0.\n",
    "    We first seperate TDC's apart and then merge them, which creates nulls.\n",
    "    The nulls for TDC2 are back filled i.e. if a cell N is null then it's filled \n",
    "    with the last cell <N which isn't null. TDC1 nulls aren't filled but rather dropped\n",
    "    because we are really interested in TDC2. Finally we calculate the time difference\n",
    "    between TD1 and TDC2. Finally we gate the difference by 5*10^4 ns = 50 us.\n",
    "    '''\n",
    "    if filename is not None:\n",
    "        tpx_df =pd.read_csv(filename,\n",
    "                    sep=':',\n",
    "                    error_bad_lines=False,\n",
    "                    warn_bad_lines=False,\n",
    "                    header=None)\n",
    "    elif tdc_df is not None:\n",
    "        tpx_df = tdc_df\n",
    "    else:\n",
    "        raise(Exception('Either a filename or a tdc data frame needs to be given!'))\n",
    "    tpx_df.columns = ['tdc','time']\n",
    "\n",
    "    print('tpx_df nulls\\n',tpx_df.isna().sum())\n",
    "    tdc_one = tpx_df[tpx_df.tdc == 'TDC1']\n",
    "    tdc_two = tpx_df[tpx_df.tdc == 'TDC2']\n",
    "    time_df = tdc_one[['time']].join(tdc_two.time,how='outer',lsuffix='1',rsuffix='2')\n",
    "    time_df['time2'] = time_df['time2'].fillna(method='bfill')\n",
    "    time_df['time1'] = time_df['time1'].fillna(method='bfill')\n",
    "\n",
    "    #time_df.dropna(inplace=True)\n",
    "    time_df = time_df.astype(np.float64)\n",
    "    time_df['delta_t'] = (time_df.time2-time_df.time1)*1e9\n",
    "    time_df.reset_index(inplace=True)\n",
    "    time_df.drop('index',axis=1,inplace=True)\n",
    "    #time_df = time_df[np.abs(time_df.delta_t)< 5e3]\n",
    "    if debug:\n",
    "        return tpx_df, tdc_one, tdc_two, time_df\n",
    "    else:\n",
    "        print(time_df.head(10))\n",
    "        return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,tdc_one_bg, tdc_two_bg,_= preproces_tdcs('tdc8.txt',debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_processing(df_str,debug=False):\n",
    "    if debug:\n",
    "        tpx_data = df_str\n",
    "    else:\n",
    "        tpx_data = pd.read_csv(StringIO(df_str),index_col=False)\n",
    "    tpx_data['totx'] = tpx_data['tot']*tpx_data['x']\n",
    "    tpx_data['toty'] = tpx_data['tot']*tpx_data['y']\n",
    "    tpx_data['toa1'] = (tpx_data['toa']-tpx_data['tdc1'])\n",
    "    tpx_data['toa2'] = (tpx_data['tdc2']-tpx_data['toa'])\n",
    "    tpx_data['delta_t'] = (tpx_data['tdc2']-tpx_data['tdc1'])\n",
    "    tpx_data['ones'] =1\n",
    "    batches = tpx_data.groupby('batch').sum()\n",
    "    batches['toa1'] = batches['toa1']/batches['ones']\n",
    "    batches['toa2'] = batches['toa2']/batches['ones']\n",
    "    batches['delta_t'] = batches['delta_t']/batches['ones']\n",
    "    batches['x'] = batches['totx']/batches['tot']\n",
    "    batches['y'] = batches['toty']/batches['tot']\n",
    "    batches.drop(['toa','tot','tdc1','tdc2','totx','toty','ones'],axis=1,inplace=True)\n",
    "    if debug:\n",
    "        return batches\n",
    "    return batches.to_csv(header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NTOTBATCHES = -1\n",
    "NBATCH = 20_000\n",
    "BEGINLINE= 0\n",
    "line_counter = 0\n",
    "NLINES = -1\n",
    "batch = 0\n",
    "\n",
    "tdc_updated = False\n",
    "\n",
    "t1_eps = 9e-4 #tdc1 tolerance\n",
    "t2_eps = 3e-6 #tdc2 tolerance\n",
    "\n",
    "x_threshold = 15\n",
    "y_threshold = 15\n",
    "xmax = 0\n",
    "xmin = 1000 # detector has only 256x256 pixels\n",
    "ymax = 0\n",
    "ymin = 1000 # detector has only 256x256 pixels\n",
    "\n",
    "batch_lines = ''\n",
    "df_str = ''\n",
    "\n",
    "many_electron_reject = 0\n",
    "tdc1_reject = 0\n",
    "tdc2_reject= 0\n",
    "\n",
    "toa_overflow_counter = 0\n",
    "tdc1_overflow_counter = 0\n",
    "tdc2_overflow_counter = 0\n",
    "\n",
    "toa_overflow_threshold = (25*2**30/1e9)\n",
    "tdc_overflow_threshold = (25*2**32/1e9)\n",
    "\n",
    "tdc1_overflow = False\n",
    "tdc2_overflow = False\n",
    "toa_overflow = False\n",
    "\n",
    "overflow_threshold = 10    # sets after which we start checking overflow\n",
    "\n",
    "toa = 0\n",
    "\n",
    "\n",
    "\n",
    "tdc1_iter = tdc_one_bg.time.iteritems()\n",
    "_ ,tdc1 = next(tdc1_iter)\n",
    "_ , tdc1_next = next(tdc1_iter)\n",
    "\n",
    "\n",
    "tdc2_iter = tdc_two_bg.time.iteritems()\n",
    "_ ,tdc2 = next(tdc2_iter)\n",
    "_ , tdc2_next = next(tdc2_iter)\n",
    "\n",
    "header = 'batch,x,y,toa1,toa2,delta_t\\n'\n",
    "\n",
    "\n",
    "with open('preprocessed110.csv','w') as wfile:\n",
    "    wfile.write('')\n",
    "\n",
    "import re\n",
    "re_search = re.compile('\\w+:')\n",
    "with open('converted8.txt','r') as rfile:\n",
    "    with open('preprocessed110.csv','a') as afile:\n",
    "        afile.write(header)\n",
    "        \n",
    "        def overflow_corr(num,num_counter,num_threshold): #corrects for overflow\n",
    "            return num + num_counter*num_threshold\n",
    "        \n",
    "        for line in rfile:\n",
    "            line_counter+=1\n",
    "            if line_counter < BEGINLINE:\n",
    "    #            toa_overflow_counter =3 #for 12_000_000\n",
    "                continue\n",
    "                \n",
    "            if line_counter %1_000_000 == 0:\n",
    "                print(f'{line_counter:_} lines read')\n",
    "\n",
    "            \n",
    "            if batch % NBATCH == 0 and batch>0 and df_str != '':\n",
    "                df_str='toa,tot,x,y,tdc1,tdc2,batch\\n'+df_str\n",
    "                to_write = final_processing(df_str)\n",
    "                afile.write(to_write)\n",
    "                to_write = ''\n",
    "                #break\n",
    "                df_str = ''\n",
    "                print(f'\\nBatch numer {batch:_} is written')\n",
    "                print(f'{line_counter:_} lines read')\n",
    "                print('-----')\n",
    "\n",
    "\n",
    "                \n",
    "            if batch == NTOTBATCHES:\n",
    "                print('NBATCHES reached')\n",
    "                break\n",
    "            if line_counter == NLINES:\n",
    "                print('NLINES reached')\n",
    "                break\n",
    "\n",
    "                    \n",
    "############################################ TOA #######################################\n",
    "                \n",
    "                \n",
    "            str_list = line.split('TOA:')\n",
    "            try:\n",
    "                toa_prev = toa\n",
    "                toa = np.float64(str_list[1].split(',')[0])\n",
    "                toa2 = toa\n",
    "                toa = overflow_corr(toa,toa_overflow_counter,toa_overflow_threshold)\n",
    "                    \n",
    "                if toa_prev > toa + overflow_threshold:\n",
    "                    \n",
    "                    toa_overflow_counter += 1\n",
    "                    #print('toa2 %s tdc1 %s' % (toa2,tdc1))\n",
    "                    #print('toa_prev %s toa %s toa_prev-toa %s' % (toa_prev,toa,toa_prev-toa))\n",
    "                    toa += toa_overflow_threshold\n",
    "                    print('### TOA Overflow NO %s' %toa_overflow_counter )\n",
    "                    print('toa_prev %s toa %s tdc1 %s tdc2 %s'  % (toa_prev,toa,tdc1,tdc2))\n",
    "                    \n",
    "\n",
    "                \n",
    "            except IndexError: # This only happens for tdc lines\n",
    "                continue\n",
    "\n",
    "                \n",
    "############################################ TDC2  #######################################\n",
    "\n",
    "                \n",
    "            # tdc2 iterator is only updated when the difference of toa with the current tdc2\n",
    "            # is greater than the difference of toa with the next tdc2\n",
    "            while abs(toa-tdc2) >= abs(toa-tdc2_next):\n",
    "                tdc2 = tdc2_next\n",
    "                _ ,tdc2_next = next(tdc2_iter)\n",
    "                \n",
    "                # Handle overflow\n",
    "                tdc2_next = overflow_corr(tdc2_next,tdc2_overflow_counter,tdc_overflow_threshold)\n",
    "                \n",
    "                if tdc2 > tdc2_next+overflow_threshold:\n",
    "                   # print('tdc2 %s tdc2_next %s tdc1 %s toa %s' % (tdc2,tdc2_next ,tdc1,toa))\n",
    "\n",
    "                    tdc2_overflow_counter += 1\n",
    "                    tdc2_next += tdc_overflow_threshold\n",
    "                    print('### TDC2 Overflow NO %s' %tdc2_overflow_counter )\n",
    "                    print('tdc2 %s tdc2_next %s tdc1 %s toa %s' % (tdc2,tdc2_next ,tdc1,toa))\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "                tdc_updated = True\n",
    "    \n",
    "    \n",
    "############################################ MANY ELECTRON  #######################################\n",
    "\n",
    "            # We want to gate >1 electron events. This is achieved by putting a max-min threshold\n",
    "            # on x and y. \n",
    "            if tdc_updated:\n",
    "                if abs(xmax-xmin) < x_threshold and abs(ymax-ymin) < y_threshold:\n",
    "                    df_str = df_str + batch_lines\n",
    "                    batch += 1\n",
    "                else:\n",
    "                    if np.random.rand()<1/2500:\n",
    "                        many_e = pd.read_csv(StringIO(header+batch_lines))\n",
    "                        try:\n",
    "                            many_e.plot(x='x',y='y',linestyle='None',marker='o')\n",
    "                            plt.show()\n",
    "                        except:\n",
    "                            None\n",
    "                    many_electron_reject +=1\n",
    "                    if many_electron_reject % 5_000==0:\n",
    "                        print(f'{many_electron_reject:_} batches were rejected due to many electrons')\n",
    "\n",
    "\n",
    "                    \n",
    "                tdc_updated = False\n",
    "                batch_lines =''\n",
    "                xmax = 0\n",
    "                xmin = 1000\n",
    "                ymax = 0\n",
    "                ymin = 1000\n",
    "                \n",
    "############################################ TDC1  #######################################\n",
    "\n",
    "\n",
    "            # when the difference bw tdc1 and toa exceeds the threshold we need to update tdc1\n",
    "            while toa-tdc1>=t1_eps:\n",
    "                tdc1 = tdc1_next\n",
    "                _ ,tdc1_next = next(tdc1_iter)\n",
    "                \n",
    "                # Handle overflow\n",
    "                tdc1_next = overflow_corr(tdc1_next,tdc1_overflow_counter,tdc_overflow_threshold)\n",
    "                \n",
    "                if tdc1 > tdc1_next + overflow_threshold:\n",
    "                    tdc1_overflow_counter += 1\n",
    "                   # print('tdc1 %s tdc1_next %s tdc2 %s toa %s' % (tdc1,tdc1_next ,tdc2,toa))\n",
    "\n",
    "                    tdc1_next += tdc_overflow_threshold\n",
    "                    print('### TDC1 Overflow NO %s' %tdc1_overflow_counter )\n",
    "                    print('tdc1 %s tdc1_next %s tdc2 %s toa %s' % (tdc1,tdc1_next ,tdc2,toa))\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            if toa-tdc1 >=0 and toa-tdc1<t1_eps:  \n",
    "                # We assume that tdc1 signal must be the first signal hence >0\n",
    "                # if the difference between time of arrival (toa) and tdc1 signal\n",
    "                # is below threshold and toa-tdc2 is below threshold we write into the file\n",
    "                if abs(toa-tdc2) < t2_eps:\n",
    "                    line = ''.join(re_search.split(line))[:-1] + (', %s , %s , %s\\n' % (tdc1,tdc2,batch))\n",
    "                    batch_lines = batch_lines + line\n",
    "                    x,y = line.split(',')[2:4]\n",
    "                    x,y = int(x),int(y)\n",
    "                    xmax = max(x,xmax)\n",
    "                    xmin = min(x,xmin)\n",
    "                    ymax = max(y,ymax)\n",
    "                    ymin = min(y,ymin)\n",
    "                else:\n",
    "                    tdc2_reject +=1\n",
    "                    if tdc2_reject %100_000 == 0:\n",
    "                        print(f'{tdc2_reject:_} lines were rejected due to tdc2 mismatch')\n",
    "            else:\n",
    "                tdc1_reject += 1\n",
    "                if tdc1_reject %100_000 == 0:\n",
    "                        print(f'{tdc1_reject:_} lines were rejected due to tdc1 mismatch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=pd.read_csv('preprocessed110.csv')\n",
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp2 = pd.read_csv('preprocessed11.csv')\n",
    "tmp2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2=final_processing(tmp2,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x,y=line_hist(tmp.delta_t*1e9,bins=np.linspace(4785,4795,105),normalized=False,linestyle='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x*y).sum()/y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=line_hist(tmp.delta_t*1e9,bins=np.linspace(0,10000,5000),normalized=False,linestyle='None')\n",
    "ycs = np.cumsum(y)\n",
    "plt.plot(x,ycs/ycs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tmp['delta_t']*1e9<4795).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=tmp[tmp['delta_t']*1e9<4795],x='x',y='y',bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.loc[26_715].toa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.longdouble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_processing(df_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('preprocessed110.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.finfo('longdouble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.finfo('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
